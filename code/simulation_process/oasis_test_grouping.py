import asyncio
import os
import logging
import ast
import random 
from datetime import datetime
from collections import defaultdict
from typing import List, Set, Dict, Any, Iterable, Tuple, Optional
import sqlite3
import pandas as pd
from tqdm import tqdm
import numpy as np 
from import Dict, Optional
from camel.models import ModelFactory
from camel.types import ModelPlatformType, ModelType
from camel.models import VLLMModel, DeepSeekModel

from attitude_annotator import AttitudeAnnotator

import oasis
from oasis import (ActionType, LLMAction, ManualAction)
# ã€!! å…³é”® !!ã€‘ æˆ‘ä»¬ç°åœ¨åªå¯¼å…¥ "é‡" çš„ graph_generator
from oasis.social_agent.agents_generator import (
    generate_twitter_agent_graph
)
from oasis.social_agent import AgentGraph
from oasis.social_platform.config import UserInfo
from oasis.social_platform import Platform


# Tier 1: "é‡" LLM Agents (åˆå§‹åŒ–æ…¢, è¿è¡Œæ…¢)
TIER_1_LLM_GROUPS = {
    "æƒå¨åª’ä½“/å¤§V",
    "æ´»è·ƒKOL",
    "æ´»è·ƒåˆ›ä½œè€…",
    "æ™®é€šç”¨æˆ·" 
}

# Tier 2: "è½»" ABM Agents (åˆå§‹åŒ–å¿«, è¿è¡Œå¿«)
TIER_2_HEURISTIC_GROUPS = {
    "æ½œæ°´ç”¨æˆ·"
}
#æ—¶é—´ä¸ºï¼š2025-06-02 16:30:00
CALIBRATION_END= "2025-06-02T16:30:00"

async def log_agent_attitudes(
    env: oasis.OasisEnv, 
    db_path: str, 
    current_step: int, 
    attitude_columns: List[str]
):
    """
    [é‡å†™] åœ¨æ¯ä¸ªæ—¶é—´æ­¥ç»“æŸæ—¶ï¼Œè®°å½• *æ¯ä¸ª* agent çš„æ€åº¦ã€‚
    - ABM Agent: è®°å½•å…¶ 'internal_state' (æ¥è‡ª .attitude_scores)
    - LLM Agent: è®°å½•å…¶ 'external_expression' (æ¥è‡ªå…¶ *å½“å‰æ—¶é—´æ­¥* å¸–å­çš„å¹³å‡åˆ†)
    
    å‡è®¾çš„è¡¨ç»“æ„ (ä¾‹å¦‚ 'log_attitude_lifestyle_culture'):
    CREATE TABLE ... (
        time_step INTEGER,
        user_id TEXT,
        agent_id INTEGER,
        agent_type TEXT,
        metric_type TEXT,
        attitude_score REAL
    );
    """
    logger = logging.getLogger("AttitudeLogger")
    logger.info(f"[Step {current_step}] æ­£åœ¨è®°å½• *æ¯ä¸ª* Agent çš„æ€åº¦...")
    
    all_agents = list(env.agent_graph.get_agents())
    
    # å‡†å¤‡ä¸€ä¸ªåˆ—è¡¨æ¥æ‰¹é‡æ’å…¥
    # æ ¼å¼: (table_name, time_step, user_id, agent_id, agent_type, metric_type, score)
    batch_insert_data = []

    # --- 1. å¤„ç† ABM (Tier 2) - å†…éƒ¨çŠ¶æ€ ---
    # (è¿™éƒ¨åˆ†åœ¨å†…å­˜ä¸­å®Œæˆï¼Œä¸éœ€è¦æ•°æ®åº“)
    abm_agent_count = 0
    for agent_id, agent in all_agents:
        if agent.group in TIER_2_HEURISTIC_GROUPS:
            if hasattr(agent, 'attitude_scores') and isinstance(agent.attitude_scores, dict):
                abm_agent_count += 1
                
                # å¤åˆ¶åˆ†æ•°å¹¶è®¡ç®—æ€»å¹³å‡åˆ†
                scores_dict = agent.attitude_scores.copy()
                valid_scores = [scores_dict.get(col, 0.0) for col in attitude_columns if scores_dict.get(col) is not None]
                scores_dict['attitude_average'] = np.mean(valid_scores) if valid_scores else 0.0
                
                # [!! ä¿®æ”¹: æ•è·ä¸¤ä¸ª ID !!]
                agent_sim_id = agent.agent_id # (e.g., 1001)
                user_id_str = agent.user_info.profile["other_info"].get("original_user_id") # (e.g., '1618051664')
                
                # ä¸ºè¯¥ agent çš„ 5 ä¸ªç»´åº¦å‡†å¤‡æ’å…¥æ•°æ®
                for dim_name, score_value in scores_dict.items():
                    table_name = f"log_{dim_name}"
                    batch_insert_data.append((
                        table_name,
                        current_step,
                        user_id_str,       # <-- user_id
                        agent_sim_id,      # <-- agent_id
                        'ABM',
                        'internal_state',
                        score_value
                    ))

    # --- 2. å¤„ç† LLM (Tier 1) - å¤–éƒ¨è¡¨ç° ---
    llm_agent_ids = {agent.agent_id for agent_id, agent in all_agents if agent.group in TIER_1_LLM_GROUPS}
    llm_agent_count = 0
    
    if llm_agent_ids:
        try:
            # (ä½¿ç”¨åªè¯»æ¨¡å¼æŸ¥è¯¢)
            with sqlite3.connect(f'file:{db_path}?mode=ro', uri=True) as conn:
                id_placeholders = ", ".join(["?"] * len(llm_agent_ids))
                avg_cols_sql = ", ".join([f"AVG({col})" for col in attitude_columns])
                
                # å…³é”®æŸ¥è¯¢:
                # [!! ä¿®æ”¹: æŸ¥è¯¢ agent_id (æ•´æ•°) å¹¶é€‰æ‹© user_id å’Œ agent_id !!]
                query = f"""
                SELECT 
                    user_id, 
                    agent_id,
                    {avg_cols_sql}
                FROM post
                WHERE created_at = ?                     -- åŒ¹é…å½“å‰æ—¶é—´æ­¥
                  AND agent_id IN ({id_placeholders})   -- åŒ¹é… LLM Agent ID (æ•´æ•°)
                  AND attitude_annotated = 1           -- å¿…é¡»å·²æ ‡æ³¨
                GROUP BY user_id, agent_id               -- <-- æŒ‰ä¸¤ä¸ª ID åˆ†ç»„
                """
                params = (current_step, *list(llm_agent_ids))
                
                cursor = conn.cursor()
                cursor.execute(query, params)
                rows = cursor.fetchall()
                
                llm_agent_count = len(rows) # è®°å½•å®é™…å‘å¸–çš„ agent æ•°é‡
                
                # éå† *å‘äº†å¸–* çš„ LLM agents
                for row in rows:
                    # [!! ä¿®æ”¹: æå–ä¸¤ä¸ª ID !!]
                    user_id_str = str(row[0])
                    agent_sim_id = int(row[1])
                    llm_avgs_list = list(row[2:])
                    
                    # (A) 4ä¸ªç»´åº¦çš„å¹³å‡å€¼
                    scores_dict = {col: llm_avgs_list[i] for i, col in enumerate(attitude_columns)}
                    
                    # (B) æ€»å¹³å‡å€¼
                    valid_avgs = [x for x in llm_avgs_list if x is not None]
                    scores_dict['attitude_average'] = np.mean(valid_avgs) if valid_avgs else 0.0
                    
                    # ä¸ºè¯¥ agent çš„ 5 ä¸ªç»´åº¦å‡†å¤‡æ’å…¥æ•°æ®
                    for dim_name, score_value in scores_dict.items():
                        table_name = f"log_{dim_name}"
                        batch_insert_data.append((
                            table_name,
                            current_step,
                            user_id_str,    # <-- user_id
                            agent_sim_id,   # <-- agent_id
                            'LLM',
                            'external_expression',
                            score_value
                        ))
        except sqlite3.Error as e:
            logger.error(f"[Step {current_step}] æŸ¥è¯¢ LLM å¸–å­åˆ†æ•°æ—¶å‡ºé”™: {e}")
        except Exception as e:
            logger.error(f"[Step {current_step}] å¤„ç† LLM åˆ†æ•°æ—¶æ„å¤–å‡ºé”™: {e}", exc_info=True)

    # --- 3. æ‰¹é‡å†™å…¥æ•°æ®åº“ ---
    if not batch_insert_data:
        logger.info(f"[Step {current_step}] æ²¡æœ‰æ–°çš„æ€åº¦åˆ†æ•°éœ€è¦è®°å½•ã€‚")
        return

    inserted_count = 0
    try:
        # (ä½¿ç”¨å†™æ¨¡å¼è¿æ¥)
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            # éå†æ‰€æœ‰å‡†å¤‡å¥½çš„æ•°æ®
            # [!! ä¿®æ”¹: è§£åŒ…ä¸¤ä¸ª ID !!]
            for (table_name, ts, user_id, agent_id, agent_type, metric_type, score) in batch_insert_data:
                try:
                    # [!! ä¿®æ”¹: æ’å…¥ä¸¤ä¸ª ID !!]
                    cursor.execute(
                        f"""
                        INSERT INTO {table_name} (
                            time_step, user_id, agent_id, agent_type, metric_type, attitude_score
                        ) VALUES (?, ?, ?, ?, ?, ?)
                        """,
                        (ts, user_id, agent_id, agent_type, metric_type, score)
                    )
                    inserted_count += 1
                except sqlite3.Error as e:
                    logger.error(f"[Step {current_step}] å†™å…¥æ—¥å¿—è¡¨ '{table_name}' å¤±è´¥ (Agent {agent_id}): {e}. (è¯·ç¡®ä¿è¯¥è¡¨å·²åˆ›å»º)")
                    # (ç»§ç»­å°è¯•å†™å…¥å…¶ä»–æ¡ç›®)
            
            conn.commit() # æäº¤äº‹åŠ¡
            logger.info(f"[Step {current_step}] æˆåŠŸè®°å½• {abm_agent_count} ä¸ª ABM agents å’Œ {llm_agent_count} ä¸ª LLM agents (å…± {inserted_count} æ¡åˆ†æ•°)ã€‚")
            
    except sqlite3.Error as e:
        logger.error(f"[Step {current_step}] æ‰¹é‡å†™å…¥æ€åº¦æ—¥å¿—æ—¶æ•°æ®åº“å‡ºé”™: {e}")
    except Exception as e:
        logger.error(f"[Step {current_step}] æ‰¹é‡å†™å…¥æ€åº¦æ—¥å¿—æ—¶æ„å¤–å‡ºé”™: {e}", exc_info=True)
# --- [!! å‡½æ•°é‡å†™ç»“æŸ !!] ---


async def main():
    # --- (æ—¥å¿—é…ç½®) ---
    log_dir = "./log"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    current_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    log_file_path = f"{log_dir}/oasis_test_{current_time}.log"
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler(log_file_path, encoding="utf-8"),
            logging.StreamHandler()
        ]
    )
    logger = logging.getLogger(__name__)
    logger.info(f"æ—¥å¿—å°†ä¿å­˜åˆ°: {log_file_path}")
    logger.info("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
    # --- (é…ç½®ç»“æŸ) ---
   
    model = ModelFactory.create(
        model_platform=ModelPlatformType.OPENAI_COMPATIBLE_MODEL,
        model_type="gpt-4o-mini",
        url='https://api.nuwaapi.com/v1',
        api_key='sk-tsmw9XQGmKWqE1CvpPCOG2YpLgnYdGisi54GVU0Lf0GFW9rN',
    )
    logger.info("æ¨¡å‹åˆå§‹åŒ–å®Œæ¯•ã€‚")
    
    # --- æ–°å¢ï¼šAttitudeAnnotator é…ç½®ä¸åˆå§‹åŒ– ---
    ATTITUDE_COLUMNS = [
        'attitude_lifestyle_culture',
        'attitude_sport_ent',
        'attitude_sci_health',
        'attitude_politics_econ'
    ]
    ANNOTATOR_API_KEY = 'sk-tsmw9XQGmKWqE1CvpPCOG2YpLgnYdGisi54GVU0Lf0GFW9rN'  # å¯æ”¹ä¸ºä» env è¯»å–
    ANNOTATOR_BASE_URL = 'https://api.nuwaapi.com/v1'
    ANNOTATOR_BATCH_SIZE = 200
    ANNOTATOR_CONCURRENCY = 50

    logger.info("æ­£åœ¨åˆå§‹åŒ– AttitudeAnnotator...")
    annotator = AttitudeAnnotator(
        api_key=ANNOTATOR_API_KEY,
        base_url=ANNOTATOR_BASE_URL,
        attitude_columns=ATTITUDE_COLUMNS,
        batch_size=ANNOTATOR_BATCH_SIZE,
        concurrency_limit=ANNOTATOR_CONCURRENCY
    )
    logger.info("AttitudeAnnotator åˆå§‹åŒ–å®Œæ¯•ã€‚")
    # --- (åˆå§‹åŒ–ç»“æŸ) ---
    
    available_actions = [
        ActionType.CREATE_POST,
        ActionType.LIKE_POST,
        ActionType.REPOST,
        ActionType.FOLLOW,
        ActionType.DO_NOTHING,
        ActionType.QUOTE_POST
    ]

    profile_path = "data/oasis/oasis_agent_init_3000_random.csv" 
    db_path = "data/oasis/oasis_database_3000_random.db" 
    
    
    # 1. (æ…¢é€Ÿ) åœ¨å†…å­˜ä¸­æ„å»º Agent Graph
    logger.info(f"æ­£åœ¨ä» {profile_path} æ„å»º agent graph...")
    agent_graph = await generate_twitter_agent_graph(
        profile_path=profile_path,
        model=model,
        available_actions=available_actions,
        db_path=db_path
    )
    logger.info(f"Agent graph æ„å»ºå®Œæ¯•, å…± {agent_graph.get_num_nodes()} ä¸ª agents (T1+T2)ã€‚")


    tables_to_keep = [
        'post', 
        'ground_truth_post', 
        'sqlite_sequence',
        'log_attitude_lifestyle_culture',
        'log_attitude_sport_ent',
        'log_attitude_sci_health',
        'log_attitude_politics_econ',
        'log_attitude_average'
    ]

    if os.path.exists(db_path):
        logger.warning(f"æ•°æ®åº“ {db_path} å·²å­˜åœ¨ã€‚å°†é‡ç½®è¡¨ï¼Œä½†ä¿ç•™ 'post' å’Œ 'ground_truth_post' åŠ 'log_attitude_...' è¡¨ã€‚")
        
        try:
            # 1. è¿æ¥åˆ°æ•°æ®åº“
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            # 2. è·å–æ‰€æœ‰è¡¨çš„åˆ—è¡¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            all_tables = [row[0] for row in cursor.fetchall()]
            
            tables_to_drop = []
            
            # 3. æ‰¾å‡ºæ‰€æœ‰éœ€è¦åˆ é™¤çš„è¡¨
            for table_name in all_tables:
                if table_name not in tables_to_keep:
                    tables_to_drop.append(table_name)

            # 4. é€ä¸ªåˆ é™¤è¿™äº›è¡¨
            if tables_to_drop:
                logger.warning(f"å°†åˆ é™¤ä»¥ä¸‹æ¨¡æ‹Ÿç»“æœè¡¨: {', '.join(tables_to_drop)}")
                for table_name in tables_to_drop:
                    # (ç°åœ¨ä¼šå®‰å…¨åœ°è·³è¿‡æ‰€æœ‰ 'tables_to_keep' åˆ—è¡¨ä¸­çš„è¡¨)
                    cursor.execute(f"DROP TABLE IF EXISTS {table_name}")
                conn.commit()
                logger.info("æ•°æ®åº“é‡ç½®å®Œæˆã€‚")
            else:
                logger.info("æ²¡æœ‰æ‰¾åˆ°éœ€è¦é‡ç½®çš„æ¨¡æ‹Ÿç»“æœè¡¨ã€‚")
                
        except sqlite3.Error as e:
            logger.error(f"é‡ç½®æ•°æ®åº“æ—¶å‡ºé”™: {e}")
        finally:
            if conn:
                conn.close()
                
    else:
        logger.info(f"æ•°æ®åº“ {db_path} ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°åº“ã€‚")

    # 3. (å¿«é€Ÿ) åˆ›å»ºç¯å¢ƒ
    logger.info("æ­£åœ¨åˆ›å»º Oasis ç¯å¢ƒ (oasis.make)...")
    env = oasis.make(
            agent_graph=agent_graph, 
            platform=oasis.DefaultPlatformType.TWITTER,
            database_path=db_path,
            calibration_end=CALIBRATION_END
    )


    logger.info("æ­£åœ¨æ‰§è¡Œç¯å¢ƒé‡ç½® (env.reset)...")
    await env.reset()
    logger.info("ç¯å¢ƒé‡ç½®å®Œæ¯•ã€‚")
    
    # --- [!! åˆ é™¤: å¯¹ initialize_log_table çš„è°ƒç”¨ !!] ---
    # (å·²åˆ é™¤)
    
    # åŸºç¡€æ¿€æ´»ç‡
    TIER_1_ACTIVATION_RATES = {
        "æƒå¨åª’ä½“/å¤§V": 0.8,
        "æ´»è·ƒKOL": 0.7,
        "æ´»è·ƒåˆ›ä½œè€…": 0.6,
        "æ™®é€šç”¨æˆ·": 0.3, 
    }
    TIER_2_ACTIVATION_RATES = {
        "æ½œæ°´ç”¨æˆ·": 0.1, 
    }
    
    # [!! ä¿®æ”¹: è¿è¡Œ 5 ä¸ª step !!]
    total_steps = 5
    for step in range(total_steps):
        current_step = step + 1 # (ä» 1 å¼€å§‹è®¡æ•°)
        logger.info(f"--- ğŸš€ Simulation Step {current_step} / {total_steps} ---")
        
        # --- 1. åŠ¨æ€æ¿€æ´»å™¨ (Dynamic Activator) ---
        llm_agents_to_run = [] 
        heuristic_agents_to_run = [] 
        
        total_active_pool = env.agent_graph.get_agents()
        
        for agent_id, agent in total_active_pool:
            group = agent.group # (å·²åœ¨ BaseAgent ä¸­è®¾ç½®)
            
            if group in TIER_1_LLM_GROUPS:
                activation_chance = TIER_1_ACTIVATION_RATES.get(group, 0.0)
                if random.random() < activation_chance:
                    llm_agents_to_run.append(agent) # æ·»åŠ  LLM Agent
            
            elif group in TIER_2_HEURISTIC_GROUPS:
                activation_chance = TIER_2_ACTIVATION_RATES.get(group, 0.0)
                if random.random() < activation_chance:
                    heuristic_agents_to_run.append(agent) # æ·»åŠ  Heuristic Agent

        logger.info(f"åŠ¨æ€æ¿€æ´»å™¨: {len(llm_agents_to_run)} ä¸ª LLM Agents, {len(heuristic_agents_to_run)} ä¸ª Heuristic Agents è¢«æ¿€æ´»ã€‚")

        # --- 2. æ„å»º action å­—å…¸ (ä»…ç”¨äº LLM Agents) ---
        llm_action = {
            agent: LLMAction()
            for agent in llm_agents_to_run
        }

        # --- 3. æ‰§è¡Œ Step (LLM Agents) ---
        if llm_agents_to_run:
            logger.info(f"å³å°†ä¸º {len(llm_action)} ä¸ª agents (LLM) æ‰§è¡Œ actions...")
            await env.step(llm_action)
            
        # --- 4. ã€!! ä¿®æ­£: æ‰‹åŠ¨è°ƒç”¨ Heuristic Agents !!ã€‘ ---
        if heuristic_agents_to_run:
            logger.info(f"å³å°†ä¸º {len(heuristic_agents_to_run)} ä¸ª Heuristic agents æ‰§è¡Œ .step()...")
            heuristic_tasks = [agent.step() for agent in heuristic_agents_to_run]
            await asyncio.gather(*heuristic_tasks)
        
        # --- 5. Attitude æ ‡æ³¨ (å¼‚æ­¥) ---
        try:
            logger.info(f"--- ğŸ› ï¸ Maintenance Phase (after step {current_step}) - Attitude annotation ---")
            logger.info("... æ­£åœ¨æ ‡æ³¨ 'post' è¡¨ä¸­çš„æ–°å¸–å­ (only_sim_posts=True)...")
            await annotator.annotate_table(db_path, "post", only_sim_posts=True)
            logger.info("... æ­£åœ¨æ ‡æ³¨ 'ground_truth_post' è¡¨ä¸­çš„æ–°å¸–å­ (only_sim_posts=False)...")
            await annotator.annotate_table(db_path, "ground_truth_post", only_sim_posts=False)
            logger.info("--- âœ… Attitude annotation completed ---")
        except Exception as e:
            logger.error(f"Attitude æ ‡æ³¨å¤±è´¥: {e}", exc_info=True)
        
        # --- 6. [!! æ–°å¢: è®°å½• Agent æ€åº¦æ—¥å¿— !!] ---
        # (è°ƒç”¨å·²è¢«é‡å†™çš„æ–°å‡½æ•°)
        await log_agent_attitudes(env, db_path, current_step, ATTITUDE_COLUMNS)
        # --- [!! æ–°å¢ç»“æŸ !!] ---
            
    await env.close()
    logger.info("--- Simulation Finished ---")
        


if __name__ == "__main__":
    asyncio.run(main())